{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Question-Answering Chatbot with Gradio\n",
    "\n",
    "In this exercise, we will use LangChain and OpenAI's ChatGPT [API](https://platform.openai.com/docs/guides/gpt) to build a chatbot that can answer questions using information from a set of source documents.\n",
    "\n",
    "#### Part 1: Chatbot Interface\n",
    "First let's build the interface using Gradio and get the skeleton of the chatbot in place. \n",
    "\n",
    "For the time being, we will use `send_chat_message()` to simulate the chatbot's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "\n",
    "def send_chat_message(prompt):\n",
    "    return random.choice([\"How are you?\", \"Have a great day!\", \"I'm very hungry\"])\n",
    "\n",
    "def respond(message, chat_history):\n",
    "    bot_message = send_chat_message(message)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "with gr.Blocks(title = \"âœ¨ UB DocBot âœ¨\") as demo:\n",
    "    with gr.Row():\n",
    "        gr.Image(value=\"assets/unbounce-identity-blue.png\").style(height=75)\n",
    "        gr.HTML(\"\"\"\n",
    "        <img src=\"assets/unbounce-identity-blue.png\"></div>\n",
    "        \"\"\")\n",
    "        gr.Markdown(\n",
    "        \"\"\"\n",
    "        # Hello World!\n",
    "        Welcome to âœ¨ *UB DocBot* âœ¨, an intelligent chatbot that will help find answers to your deepest, most burning questions about the Unbounce universe.\n",
    "        \"\"\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(placeholder=\"What question can I help you with today?\")\n",
    "    clear = gr.ClearButton([msg, chatbot])\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: The AI Chatbot\n",
    "Now we can build the AI chatbot component. We shall use OpenAI's chat API.\n",
    "\n",
    "##### Using Environment Files\n",
    "In the last demo, we put our secret key in plaintext in the notebook itself. This is not very secure. If we wanted to share this notebook with someone else, we would always have to remember to remove the secret key.\n",
    "\n",
    "An alternative is to use environment files and simply use the notebook to read the values from that file. To do this,\n",
    "1. Create a new blank file in the same directory and call it `.env`\n",
    "2. Write `OPENAI_API_KEY=<your secret key>`\n",
    "3. Now we can read these environment variables using `load_dotenv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys\n",
    "load_dotenv()\n",
    "openai.organization = os.getenv('OPENAI_ORG_KEY')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LangChain\n",
    "LangChain is a framework for building apps using language models. There are many off-the-shelf chains - sequences of calls to components, including other chains - that make it easy to get started. We will use the `ConversationalRetrievalChain()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "DATA_DIRECTORY = \"data\"\n",
    "VECTOR_STORE_PATH = os.path.join(DATA_DIRECTORY, \"vectors\")\n",
    "\n",
    "def load_unstructured_pdf(path):\n",
    "    \"\"\"\n",
    "    https://python.langchain.com/docs/modules/data_connection/document_loaders/how_to/pdf#using-unstructured\n",
    "    \"\"\"\n",
    "    loader = UnstructuredPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "\n",
    "def load_embeddings_from_store(path):\n",
    "    \"\"\"Load persisted embeddings.\"\"\"\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=path, embedding_function=OpenAIEmbeddings()\n",
    "    )\n",
    "    return VectorStoreIndexWrapper(vectorstore=vectorstore)\n",
    "\n",
    "\n",
    "def create_embeddings(document_path, directory):\n",
    "    \"\"\"Embedding\"\"\"\n",
    "    documents = load_unstructured_pdf(document_path)\n",
    "    return VectorstoreIndexCreator(\n",
    "        vectorstore_kwargs={\"persist_directory\": directory}\n",
    "    ).from_documents(documents)\n",
    "\n",
    "def get_embeddings():\n",
    "    \"\"\"\n",
    "    https://python.langchain.com/docs/modules/chains/popular/chat_vector_db\n",
    "    https://github.com/techleadhd/chatgpt-retrieval/blob/main/chatgpt.py\n",
    "    \"\"\"\n",
    "    if os.path.exists(VECTOR_STORE_PATH):\n",
    "        return load_embeddings_from_store()\n",
    "    else:\n",
    "        document_path = os.path.join(DATA_DIRECTORY, \"Content Library 2023-07-06.pdf\")\n",
    "        return create_embeddings(document_path, VECTOR_STORE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_PROMPT_TEMPLATE = \"\"\"Use the following pieces of context to answer the question at the end. Make sure your answer is as detailed as possible. Be witty and humourous, but always be positive and encouraging. If you don't know the answer, say a joke in response.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "def send_chat_message(prompt, chat_history, chain):\n",
    "    \"\"\"\n",
    "    Converts Gradio's chat history format to LangChain's expected \n",
    "    format and queries the chat engine for a response.\n",
    "    \"\"\"\n",
    "    langchain_history = [(msg[0], msg[1]) for msg in chat_history]\n",
    "\n",
    "    result = chain({\"question\": prompt, \"chat_history\": langchain_history})\n",
    "    print(f\"The original question is: {prompt} and the generated question is: {result['generated_question']}\")\n",
    "    return result[\"answer\"]\n",
    "\n",
    "def respond(message, chat_history):\n",
    "    bot_message = send_chat_message(message, chat_history, chain)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = get_embeddings()\n",
    "qa_prompt = PromptTemplate.from_template(template=QA_PROMPT_TEMPLATE)\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ChatOpenAI(model=\"gpt-4\", temperature=0.9),\n",
    "    retriever=index.vectorstore.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    condense_question_llm = ChatOpenAI(temperature=0, model='gpt-3.5-turbo'),\n",
    "    return_generated_question=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": qa_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(title = \"UB DocBot\") as demo:\n",
    "    with gr.Row():\n",
    "        gr.Markdown(\n",
    "        \"\"\"\n",
    "        <h1 align='left'> <img src='file/assets/unbounce-identity-blue.png' height='34' width='129'> </h1>\n",
    "        <h1 align=\"center\"> DocBot ðŸ¤–ðŸ’¬ </h1>\n",
    "        <p align='center' style='font-size: 18px;'> Meet âœ¨ DocBot âœ¨, an intelligent chatbot that helps answer your deepest questions about the Unbounce universe. </p>\n",
    "        \"\"\")\n",
    "    chatbot = gr.Chatbot(elem_id=\"ub_docbot\")\n",
    "    msg = gr.Textbox(placeholder=\"Have a question? How can I help? Start the chat.\", show_label=False)\n",
    "    clear = gr.ClearButton([msg, chatbot])\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    gr.Examples(\n",
    "        examples=[\"How do I cancel my plan?\",\n",
    "                    \"How do I upgrade plans?\",\n",
    "                    \"How do I add my domain to Unbounce?\",\n",
    "                    \"How do I connect my Wordpress domain to Unbounce?\",\n",
    "                    \"I want to transfer my domain to another account, how can I do that?\",\n",
    "                    \"How do I add a user to my account?\",\n",
    "                    \"How does Smart Traffic compare to A/B testing?\",\n",
    "                    \"What happens when I exceed account limits on my Optimize plan?\",\n",
    "                    \"Do I get access to Smart Builder with the Optimize plan?\",\n",
    "                    \"I'm currently on the annual 'Optimize plan', how do I cancel?\"\n",
    "                    ],\n",
    "        inputs=msg\n",
    "    )\n",
    "demo.launch(share=True, server_name=\"0.0.0.0\", server_port=7860)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
